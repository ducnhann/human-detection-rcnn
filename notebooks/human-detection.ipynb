{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f46075",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "import os\n",
    "import numpy as np\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import cv2\n",
    "import joblib\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "import selectivesearch\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dde5f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = os.path.join(os.path.dirname(os.getcwd()), \"data\", \"coco\")\n",
    "transform = T.ToTensor()\n",
    "\n",
    "# train_data = torchvision.datasets.CocoDetection(\n",
    "#     root=os.path.join(root_dir, \"train2017\"),\n",
    "#     annFile=os.path.join(root_dir, \"annotations\", \"instances_train2017.json\"),\n",
    "#     transform=transform\n",
    "# )\n",
    "\n",
    "val_data = torchvision.datasets.CocoDetection(\n",
    "    root=os.path.join(root_dir, \"val2017\"),\n",
    "    annFile=os.path.join(root_dir, \"annotations\", \"instances_val2017.json\"),\n",
    "    transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db2aae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch)) # Unzip the batch\n",
    "\n",
    "# train_loader = DataLoader(\n",
    "#     train_data,\n",
    "#     batch_size=32,\n",
    "#     shuffle=True,\n",
    "#     num_workers=0, \n",
    "#     collate_fn=collate_fn  \n",
    "# )\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_data,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "def compute_iou(box1, box2):\n",
    "    # box1, box2: [x_min, y_min, x_max, y_max]\n",
    "    x1_1, y1_1, x2_1, y2_1 = box1\n",
    "    x1_2, y1_2, x2_2, y2_2 = box2\n",
    "    \n",
    "    # Compute intersection\n",
    "    x1_i = max(x1_1, x1_2)\n",
    "    y1_i = max(y1_1, y1_2)\n",
    "    x2_i = min(x2_1, x2_2)\n",
    "    y2_i = min(y2_1, y2_2)\n",
    "    \n",
    "    inter_area = max(0, x2_i - x1_i) * max(0, y2_i - y1_i)\n",
    "    \n",
    "    # Compute union\n",
    "    box1_area = (x2_1 - x1_1) * (y2_1 - y1_1)\n",
    "    box2_area = (x2_2 - x1_2) * (y2_2 - y1_2)\n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "    \n",
    "    return inter_area / union_area if union_area > 0 else 0\n",
    "\n",
    "def non_max_suppression(boxes, scores, iou_threshold=0.3):\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "    \n",
    "    # Convert from [x_min, y_min, width, height] to [x_min, y_min, x_max, y_max] if needed\n",
    "    if boxes.shape[1] == 4:\n",
    "        if boxes[0, 2] < boxes[0, 0] + boxes[0, 2]:  # Check if format is [x, y, w, h]\n",
    "            x_min = boxes[:, 0]\n",
    "            y_min = boxes[:, 1]\n",
    "            x_max = boxes[:, 0] + boxes[:, 2]\n",
    "            y_max = boxes[:, 1] + boxes[:, 3]\n",
    "            boxes = np.stack([x_min, y_min, x_max, y_max], axis=1)\n",
    "    \n",
    "    # Sort by score\n",
    "    sorted_indices = np.argsort(scores)[::-1]  \n",
    "    keep_indices = []\n",
    "    \n",
    "    while len(sorted_indices) > 0:\n",
    "        # Pick the box with highest score\n",
    "        current_index = sorted_indices[0]\n",
    "        keep_indices.append(current_index)\n",
    "        \n",
    "        if len(sorted_indices) == 1:\n",
    "            break\n",
    "            \n",
    "        # Get IoU of the current box with the remaining boxes\n",
    "        current_box = boxes[current_index]\n",
    "        other_boxes = boxes[sorted_indices[1:]]\n",
    "        \n",
    "        # Calculate IoU with remaining boxes\n",
    "        ious = np.array([compute_iou(current_box, box) for box in other_boxes])\n",
    "        \n",
    "        # Keep boxes with IoU less than threshold\n",
    "        mask = ious < iou_threshold\n",
    "        sorted_indices = sorted_indices[1:][mask]\n",
    "    \n",
    "    return keep_indices\n",
    "\n",
    "def get_region_proposals(image, scales=[200, 300, 400, 500, 600, 800], sigma=0.9, min_size=5, max_proposals=3000):\n",
    "    proposals = []\n",
    "\n",
    "    for scale in scales:\n",
    "        img_lbl, regions = selectivesearch.selective_search(\n",
    "            image, scale=scale, sigma=sigma, min_size=min_size)\n",
    "    \n",
    "        for r in regions:\n",
    "            x, y, w, h = r['rect']\n",
    "\n",
    "            if w < 10 or h < 10 or w * h < 200 or w/h > 5 or h/w > 5:\n",
    "                continue\n",
    "            proposals.append([x, y, x + w, y + h])\n",
    "    \n",
    "    # Remove duplicates based on IoU\n",
    "    if len(proposals) > 0:\n",
    "        proposals = np.array(proposals)\n",
    "        scores = np.ones(len(proposals))  # Dummy scores for NMS\n",
    "        keep_indices = non_max_suppression(proposals, scores, iou_threshold=0.6)\n",
    "        proposals = proposals[keep_indices]\n",
    "    \n",
    "    return proposals[:max_proposals]\n",
    "\n",
    "def select_regions(proposals, gt_boxes, iou_pos=0.4, iou_neg=0.1):\n",
    "    positive_regions = []\n",
    "    negative_regions = []\n",
    "    \n",
    "    for proposal in proposals:\n",
    "        max_iou = 0\n",
    "        for gt_box in gt_boxes:\n",
    "            iou = compute_iou(proposal, gt_box)\n",
    "            max_iou = max(max_iou, iou)\n",
    "        \n",
    "        if max_iou >= iou_pos:\n",
    "            positive_regions.append(proposal)\n",
    "        elif max_iou < iou_neg:\n",
    "            negative_regions.append(proposal)\n",
    "    \n",
    "    return positive_regions, negative_regions\n",
    "\n",
    "cnn = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "\n",
    "cnn = torch.nn.Sequential(\n",
    "    *list(cnn.children())[:-1]  # Remove the adaptive pooling and classification layers\n",
    ")\n",
    "cnn.eval()\n",
    "cnn.to(device)\n",
    "\n",
    "preprocess = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToPILImage(), \n",
    "    torchvision.transforms.Resize((256)),  \n",
    "    torchvision.transforms.CenterCrop((224)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], # Commonly used values for ImageNet https://docs.pytorch.org/vision/0.8/models.html\n",
    "                                     std=[0.229, 0.224, 0.225])  \n",
    "])\n",
    "\n",
    "def extract_features(image, regions, cnn, preprocess, device):\n",
    "    \"\"\"\n",
    "    Extract 1280-dim features from regions using ResNet.\n",
    "    \n",
    "    Args:\n",
    "        image: Numpy array [H, W, 3] in BGR format\n",
    "        regions: Numpy array [N, 4] with [x_min, y_min, x_max, y_max]\n",
    "        cnn: Pre-trained ResNet model\n",
    "        preprocess: Transform pipeline\n",
    "        device: torch.device\n",
    "    \n",
    "    Returns:\n",
    "        Numpy array [N, 1280] with features\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    for region in regions:\n",
    "        x_min, y_min, x_max, y_max = region.astype(int) \n",
    "\n",
    "        # Ensure the region is within the image bounds\n",
    "        x_min, x_max = max(0, x_min), min(image.shape[1], x_max)\n",
    "        y_min, y_max = max(0, y_min), min(image.shape[0], y_max)\n",
    "\n",
    "        if x_max <= x_min or y_max <= y_min:\n",
    "            continue\n",
    "        region_img = image[y_min:y_max, x_min:x_max, :]\n",
    "        region_img = cv2.cvtColor(region_img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "        region_tensor = preprocess(region_img).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            feature = cnn(region_tensor).squeeze()  # [1280]\n",
    "        features.append(feature.cpu().numpy())\n",
    "    return np.array(features) if features else np.empty((0, 1280))\n",
    "\n",
    "def prepare_training_data(train_loader, cnn, preprocess, device, start_image, max_images=2500):\n",
    "    \"\"\"\n",
    "    Prepare features and targets for SVM and bounding box regression.\n",
    "    \n",
    "    Returns:\n",
    "        features: [N, 1280] array of CNN features\n",
    "        labels: [N] array of class labels (1 for human, 0 for background)\n",
    "        bboxes_gt: [N, 4] array of ground-truth boxes for positive regions\n",
    "        bboxes_pred: [N, 4] array of proposed boxes for positive regions\n",
    "    \"\"\"\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_bboxes_gt = []\n",
    "    all_bboxes_pred = []\n",
    "    pos_matched_features = []\n",
    "\n",
    "    subset_indices = list(range(start_image, min(start_image + max_images, len(train_data))))\n",
    "    subset_dataset = Subset(train_loader.dataset, subset_indices)\n",
    "    subset_loader = DataLoader(subset_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "    image_count = 0\n",
    "    for i, (images, targets) in enumerate(subset_loader):\n",
    "        \n",
    "        if image_count >= max_images:\n",
    "            break\n",
    "            \n",
    "        image_count += 1\n",
    "        actual_image_idx = start_image + i  # For logging purposes\n",
    "        print(f\"Processing image {actual_image_idx} (batch progress: {image_count}/{max_images})\")\n",
    "\n",
    "        print(f\"Image {actual_image_idx}, targets count: {len(targets[0])}\")\n",
    "        \n",
    "        image = images[0].permute(1, 2, 0).numpy() * 255\n",
    "        image = image.astype(np.uint8)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        gt_boxes = []\n",
    "        for ann in targets[0]:\n",
    "            if isinstance(ann, dict) and ann.get('category_id') == 1:  # Person class\n",
    "                if 'bbox' in ann and len(ann['bbox']) == 4:\n",
    "                    x, y, w, h = ann['bbox']\n",
    "                    gt_boxes.append([float(x), float(y), float(x + w), float(y + h)])\n",
    "        \n",
    "        gt_boxes = np.array(gt_boxes)\n",
    "        \n",
    "        if len(gt_boxes) == 0:\n",
    "            print(f\"No ground truth boxes found for image {actual_image_idx}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Found {len(gt_boxes)} ground truth person boxes\")\n",
    "        \n",
    "        proposals = get_region_proposals(image)\n",
    "        print(f\"Generated {len(proposals)} region proposals\")\n",
    "\n",
    "        pos_regions, neg_regions = select_regions(proposals, gt_boxes)\n",
    "        print(f\"Selected {len(pos_regions)} positive and {len(neg_regions)} negative regions\") \n",
    "\n",
    "        pos_regions = pos_regions[:min(len(pos_regions), 600)]  \n",
    "        neg_regions = neg_regions[:min(len(neg_regions), int(len(pos_regions)*3))] \n",
    "        \n",
    "        regions = pos_regions + neg_regions\n",
    "        labels = [1] * len(pos_regions) + [0] * len(neg_regions)\n",
    "        \n",
    "        if not regions:\n",
    "            print(f\"No regions found for image {actual_image_idx}\")\n",
    "            continue\n",
    "        \n",
    "        features = extract_features(image, regions, cnn, preprocess, device) # [N, 1280]\n",
    "        if features.shape[0] != len(labels):\n",
    "            print(f\"Feature shape mismatch for image {actual_image_idx}: {features.shape[0]} vs {len(labels)}\")\n",
    "            continue\n",
    "        \n",
    "        # Match positive regions to ground-truth boxes for regression\n",
    "        pos_bboxes_pred = []\n",
    "        pos_bboxes_gt = []\n",
    "        pos_features_for_regression = []\n",
    "\n",
    "        for pos_idx, pred_box in enumerate(pos_regions):\n",
    "            max_iou = 0\n",
    "            best_gt = None\n",
    "            for gt_box in gt_boxes:\n",
    "                iou = compute_iou(pred_box, gt_box)\n",
    "                if iou > max_iou:\n",
    "                    max_iou = iou\n",
    "                    best_gt = gt_box \n",
    "\n",
    "            if max_iou >= 0.5:\n",
    "                pos_bboxes_pred.append(pred_box)\n",
    "                pos_bboxes_gt.append(best_gt)\n",
    "                \n",
    "                if pos_idx < features.shape[0]:\n",
    "                    pos_features_for_regression.append(features[pos_idx])\n",
    "\n",
    "        if len(regions) > 0:\n",
    "            pos_matched_features.append(pos_features_for_regression)\n",
    "            all_features.append(features)\n",
    "            all_labels.append(labels)\n",
    "            all_bboxes_gt.extend(pos_bboxes_gt)\n",
    "            all_bboxes_pred.extend(pos_bboxes_pred)\n",
    "    \n",
    "    if not all_features:\n",
    "        print(\"No images with valid features found in this batch. Returning empty arrays.\")\n",
    "        return (np.empty((0, 1280)),  # Empty features array with right dimension\n",
    "                np.array([]),         # Empty labels\n",
    "                np.array([]),         # Empty gt boxes\n",
    "                np.array([]),         # Empty pred boxes\n",
    "                np.empty((0, 1280)))  # Empty matched features\n",
    "    \n",
    "    print(f\"Total processed images with features: {len(all_features)}\")\n",
    "    print(f\"Feature shapes: {[f.shape for f in all_features]}\")\n",
    "    \n",
    "    all_features = np.vstack(all_features)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    all_bboxes_gt = np.array(all_bboxes_gt)\n",
    "    all_bboxes_pred = np.array(all_bboxes_pred)\n",
    "    \n",
    "    flat_pos_features = []\n",
    "    for features_list in pos_matched_features:\n",
    "        flat_pos_features.extend(features_list)\n",
    "    \n",
    "    pos_matched_features_array = np.array(flat_pos_features) if flat_pos_features else np.empty((0, 1280))\n",
    "    \n",
    "    print(f\"Final shapes - Features: {all_features.shape}, Labels: {all_labels.shape}\")\n",
    "    print(f\"Positive samples: {np.sum(all_labels)}, Negative samples: {np.sum(all_labels == 0)}\")\n",
    "    \n",
    "    return all_features, all_labels, all_bboxes_gt, all_bboxes_pred, pos_matched_features_array\n",
    "\n",
    "def compute_offsets(pred_box, gt_box):\n",
    "    \"\"\"Compute normalized offsets for regression.\"\"\"\n",
    "    x_min_p, y_min_p, x_max_p, y_max_p = pred_box\n",
    "    x_min_g, y_min_g, x_max_g, y_max_g = gt_box\n",
    "    w_p, h_p = x_max_p - x_min_p, y_max_p - y_min_p\n",
    "    w_g, h_g = x_max_g - x_min_g, y_max_g - y_min_g\n",
    "    dx = (x_min_g - x_min_p) / w_p\n",
    "    dy = (y_min_g - y_min_p) / h_p\n",
    "    dw = np.log(w_g / w_p)\n",
    "    dh = np.log(h_g / h_p)\n",
    "    return [dx, dy, dw, dh]\n",
    "\n",
    "def train_bbox_regressor(features, bboxes_pred, bboxes_gt):\n",
    "    offsets = np.array([compute_offsets(pred, gt) for pred, gt in zip(bboxes_pred, bboxes_gt)])\n",
    "    regressors = []\n",
    "    for i in range(4):  # dx, dy, dw, dh\n",
    "        regr = GradientBoostingRegressor(\n",
    "            n_estimators=100, \n",
    "            learning_rate=0.1,\n",
    "            max_depth=3\n",
    "        )\n",
    "        regr.fit(features, offsets[:, i])\n",
    "        regressors.append(regr)\n",
    "        \n",
    "    return regressors \n",
    "\n",
    "# Preprocess features\n",
    "def preprocess_features(features, labels):\n",
    "    valid_mask = ~np.isnan(features).any(axis=1) & (features != 0).any(axis=1)\n",
    "    features = features[valid_mask]\n",
    "    labels = labels[valid_mask]\n",
    "    scaler = StandardScaler()\n",
    "    features_scaled = scaler.fit_transform(features)\n",
    "    return features_scaled, labels, scaler\n",
    "\n",
    "# Train SVM\n",
    "def train_svm(features, labels):\n",
    "    features_scaled, labels, scaler = preprocess_features(features, labels)\n",
    "    svm = LinearSVC(C=1.0, max_iter=2000, class_weight='balanced')\n",
    "    svm.fit(features_scaled, labels)\n",
    "\n",
    "    return svm, scaler\n",
    "def visualize_detections(image, detections, gt_boxes=None, threshold=0.5, save_path=None):\n",
    "\n",
    "    # Convert BGR to RGB for display\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Create figure and axis\n",
    "    fig, ax = plt.subplots(1, figsize=(12, 9))\n",
    "    ax.imshow(image_rgb)\n",
    "    \n",
    "    # Draw detections\n",
    "    for det in detections:\n",
    "        if det['score'] < threshold:\n",
    "            continue\n",
    "            \n",
    "        x, y, w, h = det['bbox']\n",
    "        rect = patches.Rectangle((x, y), w, h, linewidth=2, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "        ax.text(x, y-10, f\"Person: {det['score']:.2f}\", color='red', fontsize=10, weight='bold')\n",
    "    \n",
    "    if gt_boxes is not None:\n",
    "            for box in gt_boxes:\n",
    "                # COCO ground truth boxes are in [x, y, w, h] format\n",
    "                if len(box) == 4:\n",
    "                    x, y, w, h = box  \n",
    "                    rect = patches.Rectangle((x, y), w, h, linewidth=2, edgecolor='g', facecolor='none')\n",
    "                    ax.add_patch(rect)\n",
    "    \n",
    "    # Add legend\n",
    "    red_patch = patches.Patch(color='red', label='Detection')\n",
    "    if gt_boxes is not None:\n",
    "        green_patch = patches.Patch(color='green', label='Ground Truth')\n",
    "        ax.legend(handles=[red_patch, green_patch], loc='upper right')\n",
    "    else:\n",
    "        ax.legend(handles=[red_patch], loc='upper right')\n",
    "    \n",
    "    ax.set_title(f\"Human Detections (threshold={threshold})\")\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Save or show\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, bbox_inches='tight', dpi=150)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def detect_humans(image, cnn, preprocess, svm, scaler, regressors, device, conf_threshold=0.1, nms_threshold=0.5):\n",
    "    proposals = get_region_proposals(image)\n",
    "    features = extract_features(image, proposals, cnn, preprocess, device)\n",
    "    \n",
    "    if features.shape[0] == 0:\n",
    "        return []\n",
    "    \n",
    "    # classify using SVM\n",
    "    features_scaled = scaler.transform(features)\n",
    "    scores = svm.decision_function(features_scaled)\n",
    "\n",
    "    print(f\"SVM scores: min={scores.min() if scores.size > 0 else 'N/A'}, max={scores.max() if scores.size > 0 else 'N/A'}\")\n",
    "    print(f\"Number of scores > threshold ({conf_threshold}): {np.sum(scores > conf_threshold) if scores.size > 0 else 0}\")\n",
    "\n",
    "   # Apply regression to positive regions\n",
    "    candidate_boxes = []\n",
    "    candidate_scores = []\n",
    "    \n",
    "    for i, (score, feature, proposal) in enumerate(zip(scores, features_scaled, proposals)):\n",
    "        if score > conf_threshold:\n",
    "\n",
    "            x_min, y_min, x_max, y_max = proposal\n",
    "            w, h = x_max - x_min, y_max - y_min\n",
    "\n",
    "            # Predict each coordinate separately\n",
    "            offsets = [reg.predict(feature.reshape(1, -1))[0] for reg in regressors]\n",
    "            dx, dy, dw, dh = offsets\n",
    "            \n",
    "            if any(abs(val) > 8 for val in offsets):\n",
    "                continue\n",
    "                \n",
    "            # Apply offsets\n",
    "            x_min_refined = x_min + dx * w\n",
    "            y_min_refined = y_min + dy * h\n",
    "            w_refined = w * np.exp(dw)\n",
    "            h_refined = h * np.exp(dh)\n",
    "\n",
    "            x_max_refined = x_min_refined + w_refined\n",
    "            y_max_refined = y_min_refined + h_refined\n",
    "            \n",
    "            # Skip invalid boxes\n",
    "            if w_refined <= 0 or h_refined <= 0:\n",
    "                continue\n",
    "            # Clip to image bounds\n",
    "            x_min_refined = np.clip(x_min_refined, 0, image.shape[1])\n",
    "            y_min_refined = np.clip(y_min_refined, 0, image.shape[0])\n",
    "            x_max_refined = np.clip(x_max_refined, 0, image.shape[1])\n",
    "            y_max_refined = np.clip(y_max_refined, 0, image.shape[0])\n",
    "            \n",
    "            # Store the candidate box in [x_min, y_min, x_max, y_max] format for NMS\n",
    "            candidate_boxes.append([x_min_refined, y_min_refined, x_max_refined, y_max_refined])\n",
    "            candidate_scores.append(float(score))\n",
    "    \n",
    "    if not candidate_boxes:\n",
    "        return []\n",
    "    \n",
    "    # Apply NMS\n",
    "    candidate_boxes = np.array(candidate_boxes)\n",
    "    candidate_scores = np.array(candidate_scores)\n",
    "    keep_indices = non_max_suppression(candidate_boxes, candidate_scores, iou_threshold=nms_threshold)\n",
    "    \n",
    "    # Create final detections\n",
    "    detections = []\n",
    "    for idx in keep_indices:\n",
    "        x_min, y_min, x_max, y_max = candidate_boxes[idx]\n",
    "        # Convert to COCO format [x, y, width, height]\n",
    "        width = x_max - x_min\n",
    "        height = y_max - y_min\n",
    "        bbox = [x_min, y_min, width, height]\n",
    "        detections.append({\n",
    "            'bbox': bbox,\n",
    "            'score': float(candidate_scores[idx]),\n",
    "            'category_id': 1  # Person\n",
    "        })\n",
    "    \n",
    "    return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e625df2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_loader, cnn, preprocess, device):\n",
    "\n",
    "    batch_size = 500 \n",
    "    max_images = 2500\n",
    "    \n",
    "    all_features = None\n",
    "    all_labels = None\n",
    "    all_bboxes_gt = []\n",
    "    all_bboxes_pred = []\n",
    "    all_pos_features = []\n",
    "    \n",
    "    # Process in batches\n",
    "    for start_idx in range(0, max_images, batch_size):\n",
    "        end_idx = min(start_idx + batch_size, max_images)\n",
    "        print(f\"Processing batch of images {start_idx+1}-{end_idx}/{max_images}\")\n",
    "        \n",
    "        features, labels, bboxes_gt, bboxes_pred, pos_features = prepare_training_data(\n",
    "            train_loader, cnn, preprocess, device, \n",
    "            start_image=start_idx, \n",
    "            max_images=batch_size\n",
    "        )\n",
    "        \n",
    "        if all_features is None:\n",
    "            all_features = features\n",
    "            all_labels = labels\n",
    "        else:\n",
    "            all_features = np.vstack([all_features, features])\n",
    "            all_labels = np.concatenate([all_labels, labels])\n",
    "            \n",
    "        all_bboxes_gt.extend(bboxes_gt)\n",
    "        all_bboxes_pred.extend(bboxes_pred)\n",
    "        all_pos_features.extend(pos_features)\n",
    "        \n",
    "        # Free memory\n",
    "        del features, labels, bboxes_gt, bboxes_pred\n",
    "        import gc\n",
    "        gc.collect()\n",
    "        \n",
    "\n",
    "    all_bboxes_gt = np.array(all_bboxes_gt)\n",
    "    all_bboxes_pred = np.array(all_bboxes_pred)\n",
    "    all_pos_features = np.array(all_pos_features)\n",
    "    \n",
    "    # Train models\n",
    "    print(\"Training SVM classifier...\")\n",
    "    svm, scaler = train_svm(all_features, all_labels)\n",
    "    joblib.dump(scaler, 'scaler.pkl')\n",
    "    joblib.dump(svm, 'svm.pkl')\n",
    "    print(\"SVM training completed. Models saved.\")\n",
    "\n",
    "\n",
    "    # Free memory before training regressor\n",
    "    del all_features, all_labels\n",
    "    gc.collect()\n",
    "    \n",
    "    print(\"Training bounding box regressor...\")\n",
    "    \n",
    "    regressor = train_bbox_regressor(all_pos_features, all_bboxes_pred, all_bboxes_gt)\n",
    "    joblib.dump(regressor, 'bbox_regressor.pkl')\n",
    "    print(\"Bounding box regressor training completed. Model saved.\")\n",
    "\n",
    "    return svm, scaler, regressor\n",
    "\n",
    "svm, scaler, regressor = train_model(train_loader, cnn, preprocess, device)\n",
    "print(\"Model training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8950cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(val_data_loader, cnn, preprocess, svm, scaler, regressor, device, max_images=5):\n",
    "    all_detections = []\n",
    "    image_ids = []\n",
    "\n",
    "    for i, (images, targets) in enumerate(val_data_loader):\n",
    "        if i >= max_images:\n",
    "            break\n",
    "        print(f\"Testing image {i+1}/{max_images}\")\n",
    "\n",
    "        image_id = None\n",
    "        if targets[0] and len(targets[0]) > 0:\n",
    "            for ann in targets[0]:\n",
    "                if isinstance(ann, dict) and 'image_id' in ann:\n",
    "                    image_id = ann['image_id']\n",
    "                    break\n",
    "\n",
    "\n",
    "        image = images[0].permute(1, 2, 0).numpy() * 255\n",
    "        image = image.astype(np.uint8)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "\n",
    "        conf_threshold = 0.4 \n",
    "        nms_threshold = 0.25\n",
    "\n",
    "        detections = detect_humans(image, cnn, preprocess, svm, scaler, regressor, device, conf_threshold, nms_threshold)\n",
    "\n",
    "        for det in detections:\n",
    "            det['image_id'] = image_id\n",
    "\n",
    "        all_detections.extend(detections)\n",
    "        image_ids.append(image_id)\n",
    "     \n",
    "        gt_boxes = []\n",
    "        for ann in targets[0]:\n",
    "            if isinstance(ann, dict) and ann.get('category_id') == 1:\n",
    "                if 'bbox' in ann:\n",
    "                    gt_boxes.append(ann['bbox'])\n",
    "                                    \n",
    "        visualize_detections(image, detections, gt_boxes, threshold=0.1)\n",
    "\n",
    "    return all_detections, image_ids\n",
    "\n",
    "# Run testing\n",
    "\n",
    "svm = joblib.load('svm.pkl')\n",
    "scaler = joblib.load('scaler.pkl')\n",
    "regressor = joblib.load('bbox_regressor.pkl')\n",
    "\n",
    "print(\"Models loaded successfully\")\n",
    "\n",
    "all_detections, image_ids = test_model(val_loader, cnn, preprocess, svm, scaler, regressor, device, max_images=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3eebbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use COCO evaluation\n",
    "coco_gt = COCO(os.path.join(root_dir, \"annotations\", \"instances_val2017.json\"))\n",
    "coco_dt = coco_gt.loadRes(all_detections)\n",
    "coco_eval = COCOeval(coco_gt, coco_dt, 'bbox')\n",
    "coco_eval.params.catIds = [1]  # Person class\n",
    "coco_eval.evaluate()\n",
    "coco_eval.accumulate()\n",
    "coco_eval.summarize()\n",
    "print(\"mAP@0.5:0.95:\", coco_eval.stats[0])\n",
    "print(\"mAP@0.5:\", coco_eval.stats[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
